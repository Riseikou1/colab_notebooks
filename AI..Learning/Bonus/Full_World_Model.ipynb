{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMpTxPMaQuw3WuFRwg4DX0w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Full World Model"],"metadata":{"id":"bdXFXO4deAfp"}},{"cell_type":"markdown","source":["This shit doesn't use any q-value neither the policies(gradient policy etc..).It just learns the dynamic of the environment.\n","\n","\n","*   State Transition - If i do action A, what happens to the state?\n","*   Rewards - If i do action A in state S , what reward will i get?\n","\n","Tegeed predict hiisen ur dungiin loss-oor optimize hiigdeed yvna.Predicted value-g real outcomes-toi compare hiine.\n","\n","The agent can simulate a sequence of actions in the world model and look ahead to see which sequence of actions leads to the most reward.\n","\n"],"metadata":{"id":"5kG1Qu4NeBXS"}},{"cell_type":"code","source":["!pip install gymnasium\n","!pip install swig\n","!pip install \"gymnasium[box2d]\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oCSplHBuFVBf","executionInfo":{"status":"ok","timestamp":1731834764847,"user_tz":-540,"elapsed":9706,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"47210dc1-bbfd-47aa-aa9b-91d67a7d8c36","collapsed":true},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (1.0.0)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n","Requirement already satisfied: swig in /usr/local/lib/python3.10/dist-packages (4.2.1.post0)\n","Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (1.0.0)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (3.1.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n","Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.3.5)\n","Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.6.1)\n","Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.2.1.post0)\n"]}]},{"cell_type":"code","execution_count":21,"metadata":{"id":"Mdrd-7JJFQQc","executionInfo":{"status":"ok","timestamp":1731836879983,"user_tz":-540,"elapsed":411,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import gymnasium as gym\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","vision_model_hidden_dim=255\n","memory_model_hidden_dim = 255\n","controller_hidden_dim = 255\n","action_dim=3\n","learning_rate = 1e-4\n","num_episodes=500"]},{"cell_type":"markdown","source":["## Building the Vision Model(Convo Neural Network)"],"metadata":{"id":"vTjnN0AbXJUf"}},{"cell_type":"code","source":["class VisionModel(nn.Module):\n","    def __init__(self):\n","        super(VisionModel,self).__init__()\n","        self.conv1 = nn.Conv2d(3,32,kernel_size=8,stride=4)\n","        self.conv2 = nn.Conv2d(32,64,kernel_size=4,stride=2)\n","        self.conv3 = nn.Conv2d(64,64,kernel_size=3,stride=1)\n","        self.fc = nn.Linear(64*7*7,vision_model_hidden_dim)\n","    def forward(self,x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = F.relu(self.conv3(x))\n","        x = x.view(x.size(0),-1)  # fully connected layer-too zoriulaad flatten shaaj baina.\n","        x = F.relu(self.fc(x))\n","        return x\n"],"metadata":{"id":"xOa3ray1FfGV","executionInfo":{"status":"ok","timestamp":1731835116602,"user_tz":-540,"elapsed":613,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## Building the Memory Model(Recurrent Neural Network)"],"metadata":{"id":"hyYXtlysX9BU"}},{"cell_type":"code","source":["class MemoryModel(nn.Module):\n","    def __init__(self):\n","        super(MemoryModel,self).__init__()\n","        self.lstm = nn.LSTM(input_size = vision_model_hidden_dim,hidden_size=memory_model_hidden_dim) # long short term memory\n","\n","    def forward(self,x,hidden_state):\n","        x,hidden_state = self.lstm(x.unsqueeze(0),hidden_state)\n","        return x.squeeze(0),hidden_state\n",""],"metadata":{"id":"m_x30mVKX9LS","executionInfo":{"status":"ok","timestamp":1731835118546,"user_tz":-540,"elapsed":508,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["## Building the Controller Model(Fully Connected Neural Network)"],"metadata":{"id":"_qTSrVHOYhTT"}},{"cell_type":"code","source":["class Controller(nn.Module):\n","    def __init__(self):\n","        super(Controller,self).__init__()\n","        self.fc = nn.Linear(memory_model_hidden_dim,action_dim)\n","    def forward(self,x):\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"LBxURyNAYhZo","executionInfo":{"status":"ok","timestamp":1731835119941,"user_tz":-540,"elapsed":4,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## PreProcessing the states"],"metadata":{"id":"KgcxeuxjYhgx"}},{"cell_type":"code","source":["def preprocess_state(state):\n","    state = torch.from_numpy(state).float() / 255.0   # pixel value-g between 0-1 bolgoj normalize hiij baina.\n","    state = state.permute(2, 0, 1)  # Convert (height, width, channels) to (channels, height, width)  bairiig ni huurhun soliod ugchij baigaa.\n","    return state.unsqueeze(0)  # Add batch dimension\n"],"metadata":{"id":"6eneu6cfYhmS","executionInfo":{"status":"ok","timestamp":1731835121418,"user_tz":-540,"elapsed":4,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"Si8LBZkaYhrl"}},{"cell_type":"code","source":[" # Setting up the environment\n","env = gym.make(\"CarRacing-v3\")\n"," # Creating the models\n","vision_model = VisionModel()\n","memory_model = MemoryModel()\n","controller = Controller()\n","\n","\n","# Creating the optimizers\n","vision_optimizer = optim.Adam(vision_model.parameters(), lr=learning_rate)\n","memory_optimizer = optim.Adam(memory_model.parameters(), lr=learning_rate)\n","controller_optimizer = optim.Adam(controller.parameters(), lr=learning_rate)\n","\n","\n","# Implementing the Training Loop\n","\n","for episode in range(num_episodes):\n","    state = env.reset()\n","    hidden_state = None\n","    done = False\n","    episode_reward = 0\n","    while not done:\n","        state = preprocess_state(state)\n","        with torch.no_grad():\n","            vision_output = vision_model(state)\n","            memory_output, hidden_state = memory_model(vision_output, hidden_state or (torch.zeros(1, 1, memory_model_hidden_dim), torch.zeros(1, 1, memory_model_hidden_dim)))\n","            action = controller(memory_output).squeeze(0)\n","        next_state, reward, done, _ = env.step(action.item())  # Convert action to scalar\n","        state = next_state\n","        episode_reward += reward\n","    print(f\"Episode {episode}: Total Reward: {episode_reward}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"id":"wo-F0ve-Yhwf","executionInfo":{"status":"error","timestamp":1731835123500,"user_tz":-540,"elapsed":345,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"2183b827-5b05-484f-b004-358912705939"},"execution_count":20,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"expected np.ndarray (got tuple)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-ab1fe4202d16>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m    \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m    \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m        \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m        \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m            \u001b[0mvision_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvision_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-91bd6901b540>\u001b[0m in \u001b[0;36mpreprocess_state\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got tuple)"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NoD3o7ZfahnH"},"execution_count":null,"outputs":[]}]}