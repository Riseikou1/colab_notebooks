{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPphS6kftY009PGls3F+olj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5796da12e8ed457186ffa0ab5a749be8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c323e26eff6457582f3f50da5d67bc0","IPY_MODEL_a30930700d7247f5ad8c1e9ba97a5cec","IPY_MODEL_f3338cddf56d407ab9dec0ef52281782"],"layout":"IPY_MODEL_0c9850a364b9461aa483e1fef5a8acaa"}},"9c323e26eff6457582f3f50da5d67bc0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b70426ac543b4721ba8cd2ac628c1297","placeholder":"​","style":"IPY_MODEL_cc3582fc76c1434b9ca1f1da9257c302","value":"Epoch 29: 100%"}},"a30930700d7247f5ad8c1e9ba97a5cec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1b35269b54b43bdb5bbe93673e2c7d6","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6fdcc86a288a473496c1d6cb1c845b8f","value":2}},"f3338cddf56d407ab9dec0ef52281782":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cf3a06cad514f50a9a6fb7cd9442b50","placeholder":"​","style":"IPY_MODEL_7b2432acb6294a099c072e7d4b513b0b","value":" 2/2 [00:00&lt;00:00, 82.73it/s, v_num=0]"}},"0c9850a364b9461aa483e1fef5a8acaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"b70426ac543b4721ba8cd2ac628c1297":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc3582fc76c1434b9ca1f1da9257c302":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1b35269b54b43bdb5bbe93673e2c7d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fdcc86a288a473496c1d6cb1c845b8f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7cf3a06cad514f50a9a6fb7cd9442b50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b2432acb6294a099c072e7d4b513b0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Decoder only Transformer"],"metadata":{"id":"5Vy2lhFDko7h"}},{"cell_type":"markdown","source":["## Importing the libraries"],"metadata":{"id":"bnmAGOTKko9l"}},{"cell_type":"code","source":["!pip install pytorch-lightning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"CnyfHcYlk7If","executionInfo":{"status":"ok","timestamp":1746520403730,"user_tz":-540,"elapsed":118769,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"dc09442d-2d3f-43ba-f5c3-739e210095b4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.6.0+cu124)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n","Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.13.2)\n","Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.15)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n","Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m866.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.1.post0 torchmetrics-1.7.1\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.optim import Adam\n","from torch.utils.data import TensorDataset,DataLoader\n","\n","import pytorch_lightning as L"],"metadata":{"id":"wYGkDJj9kpGP","executionInfo":{"status":"ok","timestamp":1746520423624,"user_tz":-540,"elapsed":19889,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Creating inputs and labels for training"],"metadata":{"id":"TJU4a9m0kzs1"}},{"cell_type":"code","source":["token_to_id = {\"what\":0,\"is\":1,\"statquest\":2,\"awesome\":3,\"<EOS>\":4}"],"metadata":{"id":"EIyBHjlOkpIk","executionInfo":{"status":"ok","timestamp":1746520423649,"user_tz":-540,"elapsed":28,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["id_to_token = dict(map(reversed,token_to_id.items()))"],"metadata":{"id":"GypitNUfkpLy","executionInfo":{"status":"ok","timestamp":1746520423711,"user_tz":-540,"elapsed":59,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# we've got 2 different inputs which are :\n","# 1. what is statquest   2. statquest is what\n","#  And we want our output will be awesome.\n","\n","inputs = torch.tensor([[token_to_id[\"what\"],\n","                        token_to_id[\"is\"],\n","                        token_to_id[\"statquest\"],\n","                        token_to_id[\"<EOS>\"],\n","                        token_to_id[\"awesome\"]],\n","\n","                       [token_to_id[\"statquest\"],\n","                       token_to_id[\"is\"],\n","                       token_to_id[\"what\"],\n","                       token_to_id[\"<EOS>\"],\n","                       token_to_id[\"awesome\"]]])"],"metadata":{"id":"sJDH9XHCkpOU","executionInfo":{"status":"ok","timestamp":1746520423719,"user_tz":-540,"elapsed":28,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["labels = torch.tensor([[token_to_id[\"is\"],\n","                        token_to_id[\"statquest\"],\n","                        token_to_id[\"<EOS>\"],\n","                        token_to_id[\"awesome\"],\n","                        token_to_id[\"<EOS>\"]],\n","\n","                       [token_to_id[\"is\"],\n","                       token_to_id[\"what\"],\n","                       token_to_id[\"<EOS>\"],\n","                       token_to_id[\"awesome\"],\n","                       token_to_id[\"<EOS>\"]]])\n","\n","# we want our output will be \"is\" when input is \"what\"\n","# kinda even start predicting when taking an input.\n","# and input=\"awesome\" ==> output = \"<EOS>\" etc."],"metadata":{"id":"3t94zx8ukpRF","executionInfo":{"status":"ok","timestamp":1746520423720,"user_tz":-540,"elapsed":26,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["dataset = TensorDataset(inputs,labels)\n","dataloader = DataLoader(dataset)"],"metadata":{"id":"WiXBjAtRkpTk","executionInfo":{"status":"ok","timestamp":1746520423722,"user_tz":-540,"elapsed":26,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Position Encoding"],"metadata":{"id":"oe3My_pfu2Hm"}},{"cell_type":"code","source":["class PositionEncoding(nn.Module):\n","    def __init__(self,d_model=2,max_len=6):  # we only have 2 dim of word embedding, and max_len is just bullshit.\n","        super().__init__()\n","\n","        pe = torch.zeros(max_len,d_model)\n","\n","        position = torch.arange(start=0,end=max_len,step=1).float().unsqueeze(1)\n","        embedding_index = torch.arange(start=0,end=d_model,step=2).float()\n","\n","        div_term = 1/torch.tensor(10000.0) ** (embedding_index / d_model)\n","\n","        pe[:,0::2] = torch.sin(position * div_term)  # starting from 0, until the end, increments that shit by 2.(every other column after that)\n","        pe[:,1::2] = torch.cos(position * div_term)\n","\n","        self.register_buffer('pe',pe)\n","\n","    def forward(self,word_embeddings):\n","        return word_embeddings + self.pe[:word_embeddings.size(0),:]"],"metadata":{"id":"1IgiHgj1x9zX","executionInfo":{"status":"ok","timestamp":1746520423723,"user_tz":-540,"elapsed":26,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Attention"],"metadata":{"id":"378ZcOJ5x6q-"}},{"cell_type":"code","source":["class Attention(nn.Module):\n","    def __init__(self,d_model=2):\n","        super().__init__()\n","\n","        self.W_q = nn.Linear(in_features=d_model,out_features=d_model,bias=False)\n","        self.W_k = nn.Linear(in_features=d_model,out_features=d_model,bias=False)\n","        self.W_v = nn.Linear(in_features=d_model,out_features=d_model,bias=False)\n","\n","\n","        self.row_dim = 0\n","        self.col_dim = 1\n","\n","    def forward(self,encodings_for_q, encodings_for_k,encodings_for_v,mask=None):\n","\n","        q = self.W_q(encodings_for_q)\n","        k = self.W_k(encodings_for_k)\n","        v = self.W_v(encodings_for_v)\n","\n","        sims = torch.matmul(q,k.transpose(dim0=self.row_dim , dim1=self.col_dim))  # calculating the similarities between Queries and the Keys..\n","\n","        scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)  # nuguu neg lalariin tomyo sanaj l baigaa bizde. yazguur door, dim-d huvaagaad shaadag.\n","\n","        if mask is not None :\n","            scaled_sims = scaled_sims.masked_fill(mask=mask,value=-1e9)\n","\n","        attention_percents = F.softmax(scaled_sims,dim=self.col_dim)\n","\n","        attention_scores = torch.matmul(attention_percents,v)\n","\n","        return attention_scores\n"],"metadata":{"id":"k0STR64Du5RM","executionInfo":{"status":"ok","timestamp":1746520423748,"user_tz":-540,"elapsed":39,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Network"],"metadata":{"id":"jMXFf7SOIM6O"}},{"cell_type":"code","source":["class DecoderOnlyTransformer(L.LightningModule):\n","\n","    def __init__(self,num_tokens=4,d_model=2,max_len=6):\n","        super().__init__()\n","\n","        self.we = nn.Embedding(num_embeddings=num_tokens,embedding_dim=d_model)\n","        self.pe = PositionEncoding(d_model=d_model,max_len=max_len)\n","        self.self_attention = Attention(d_model=d_model)\n","        self.fc_layer = nn.Linear(in_features=d_model,out_features=num_tokens)\n","\n","        self.loss = nn.CrossEntropyLoss()\n","\n","    def forward(self,token_ids):\n","        word_embeddings = self.we(token_ids)\n","        position_encoded = self.pe(word_embeddings)\n","\n","        mask = torch.tril(torch.ones((token_ids.size(dim=0),token_ids.size(dim=0))))\n","        mask = mask == 0\n","\n","        self_attention_values = self.self_attention(position_encoded,position_encoded,position_encoded,mask=mask)\n","\n","        residual_connection_values = position_encoded + self_attention_values\n","\n","        fc_layer_output = self.fc_layer(residual_connection_values)\n","\n","        return fc_layer_output\n","\n","    def configure_optimizers(self):\n","        return Adam(self.parameters(),lr=0.1)\n","\n","    def training_step(self,batch,batch_idx):\n","        input_tokens,labels = batch\n","        output = self.forward(input_tokens[0])\n","        loss = self.loss(output,labels[0])\n","\n","        return loss"],"metadata":{"id":"0nyqlzFG4OqV","executionInfo":{"status":"ok","timestamp":1746520423759,"user_tz":-540,"elapsed":8,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"buBO8QxMIOX0"}},{"cell_type":"code","source":["model = DecoderOnlyTransformer(num_tokens=len(token_to_id),d_model=2,max_len=6)\n","trainer = L.Trainer(max_epochs=30)\n","trainer.fit(model,train_dataloaders=dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":434,"referenced_widgets":["5796da12e8ed457186ffa0ab5a749be8","9c323e26eff6457582f3f50da5d67bc0","a30930700d7247f5ad8c1e9ba97a5cec","f3338cddf56d407ab9dec0ef52281782","0c9850a364b9461aa483e1fef5a8acaa","b70426ac543b4721ba8cd2ac628c1297","cc3582fc76c1434b9ca1f1da9257c302","f1b35269b54b43bdb5bbe93673e2c7d6","6fdcc86a288a473496c1d6cb1c845b8f","7cf3a06cad514f50a9a6fb7cd9442b50","7b2432acb6294a099c072e7d4b513b0b"]},"collapsed":true,"id":"kNjjTa0FkpbP","executionInfo":{"status":"ok","timestamp":1746520435882,"user_tz":-540,"elapsed":12121,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"536999bd-6aec-4aff-88aa-4aa0c5dd7941"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name           | Type             | Params | Mode \n","------------------------------------------------------------\n","0 | we             | Embedding        | 10     | train\n","1 | pe             | PositionEncoding | 0      | train\n","2 | self_attention | Attention        | 12     | train\n","3 | fc_layer       | Linear           | 15     | train\n","4 | loss           | CrossEntropyLoss | 0      | train\n","------------------------------------------------------------\n","37        Trainable params\n","0         Non-trainable params\n","37        Total params\n","0.000     Total estimated model params size (MB)\n","8         Modules in train mode\n","0         Modules in eval mode\n","/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5796da12e8ed457186ffa0ab5a749be8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n"]}]},{"cell_type":"markdown","source":["## Visualising the result"],"metadata":{"id":"BQDtFChSk0gz"}},{"cell_type":"code","source":["model_input = torch.tensor([token_to_id[\"what\"],\n","                        token_to_id[\"is\"],\n","                        token_to_id[\"statquest\"],\n","                        token_to_id[\"<EOS>\"]])\n","input_length = model_input.size(dim=0)\n","\n","predictions = model(model_input)\n","predicted_id = torch.tensor([torch.argmax(predictions[-1,:])])   # means take only last time step's result. cuz we're not interested in first shits result, since we're only trying to get last token's prediction blah2.\n","predicted_ids = predicted_id\n","\n","max_length = 6\n","for i in range(input_length,max_length):\n","    if(predicted_id == token_to_id[\"<EOS>\"]):\n","        break\n","\n","    model_input = torch.cat((model_input,predicted_id))\n","\n","    predictions = model(model_input)\n","\n","    predicted_id = torch.tensor([torch.argmax(predictions[-1,:])])  # uchir ni ene shit ni, input-iin(appended version of it too) toonii row, predict bolomjtoi class-iin toonii col butsaanguut, suuliin row-oos l bid nar argmax shaaj, yamar ug predict hiihee songono shuude.\n","    predicted_ids = torch.cat((predicted_ids,predicted_id))\n","\n","print(\"Predicted Tokens :\\n\")\n","for id in predicted_ids :\n","    print(\"\\t\",id_to_token[id.item()])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Poa0i3vkpe3","executionInfo":{"status":"ok","timestamp":1746520435939,"user_tz":-540,"elapsed":43,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"95fc06cf-d8ae-405c-ce8e-db8c5b3d5f90"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Tokens :\n","\n","\t awesome\n","\t <EOS>\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bRlqPgNmkphh","executionInfo":{"status":"ok","timestamp":1746520435940,"user_tz":-540,"elapsed":4,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":12,"outputs":[]}]}