{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOOm5cgHDSgu9xpBpRlhvCM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5878d0631076460fa126e36a02f1a44f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53b701760f29410aa5e7b9a7ccd182e7","IPY_MODEL_65d7549109774bd5852dcaccaf9640e4","IPY_MODEL_4032a9b535c0460cb4ee5f5c4ac81d1b"],"layout":"IPY_MODEL_ae51278453aa48cba52481fb5f149352"}},"53b701760f29410aa5e7b9a7ccd182e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07a7cb782ef14ed28bcf9999d2aa5b33","placeholder":"​","style":"IPY_MODEL_0af8c444dbe64278afa3746c038e20b0","value":"Epoch 1999: 100%"}},"65d7549109774bd5852dcaccaf9640e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f906e925cae643c5aea685119ed566c9","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e74a91e1f70f4324a8f7600f0bc0fb9c","value":2}},"4032a9b535c0460cb4ee5f5c4ac81d1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ecde36517364dffb394a78cef934918","placeholder":"​","style":"IPY_MODEL_341a5769818a4610b77cccca788ccd92","value":" 2/2 [00:00&lt;00:00, 47.02it/s, v_num=4]"}},"ae51278453aa48cba52481fb5f149352":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"07a7cb782ef14ed28bcf9999d2aa5b33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0af8c444dbe64278afa3746c038e20b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f906e925cae643c5aea685119ed566c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e74a91e1f70f4324a8f7600f0bc0fb9c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ecde36517364dffb394a78cef934918":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"341a5769818a4610b77cccca788ccd92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62bba1196deb4f68b061fb0a30114178":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e47642b84e84b9f9cd2d48356203259","IPY_MODEL_f2c93a12e54443c98820d75110f7ead9","IPY_MODEL_6413ed9045474148b7abbd9b21293805"],"layout":"IPY_MODEL_2bb9784b37d04999b6b222b9a97a4223"}},"7e47642b84e84b9f9cd2d48356203259":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6730fec5b6e7409c9e375010980a4afa","placeholder":"​","style":"IPY_MODEL_b1c16cc9bb1148f387ad6bddbca96381","value":"Epoch 2799: 100%"}},"f2c93a12e54443c98820d75110f7ead9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37f2ea1b43c0447d94d7802c22532d97","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e86419bb9d09466e9a3de8ebb294a3b5","value":2}},"6413ed9045474148b7abbd9b21293805":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18d3fb45e7854525827293ef56643356","placeholder":"​","style":"IPY_MODEL_4e01459f799642f49b0e926ee38a23f0","value":" 2/2 [00:00&lt;00:00, 41.86it/s, v_num=5]"}},"2bb9784b37d04999b6b222b9a97a4223":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"6730fec5b6e7409c9e375010980a4afa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1c16cc9bb1148f387ad6bddbca96381":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37f2ea1b43c0447d94d7802c22532d97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e86419bb9d09466e9a3de8ebb294a3b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"18d3fb45e7854525827293ef56643356":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e01459f799642f49b0e926ee38a23f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e203536c96474a71a0fedcd3af5d3dfb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_795db0bada5a4ea69e0fb166fb2dc7cf","IPY_MODEL_bbe83ca620214f3e9f66da60d819d701","IPY_MODEL_66f6fb4296794014bcdbb37e4b4303a1"],"layout":"IPY_MODEL_31c81bc60442458c8f02c879bfdf2c4b"}},"795db0bada5a4ea69e0fb166fb2dc7cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94a606637ef3427fa8e40e6a11168c50","placeholder":"​","style":"IPY_MODEL_b2608ab09a8a452c8ed262ce7e492698","value":"Epoch 3799: 100%"}},"bbe83ca620214f3e9f66da60d819d701":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_010b1de529d7479db2ed2a889a106ee7","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5bd19ba5aa574ca79bae3112a5a101b6","value":2}},"66f6fb4296794014bcdbb37e4b4303a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e07c246a7734e68a317731ae8cca75e","placeholder":"​","style":"IPY_MODEL_2221bffae75d4e2ab155207bd278e044","value":" 2/2 [00:00&lt;00:00, 52.40it/s, v_num=6]"}},"31c81bc60442458c8f02c879bfdf2c4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"94a606637ef3427fa8e40e6a11168c50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2608ab09a8a452c8ed262ce7e492698":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"010b1de529d7479db2ed2a889a106ee7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bd19ba5aa574ca79bae3112a5a101b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e07c246a7734e68a317731ae8cca75e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2221bffae75d4e2ab155207bd278e044":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# LSTM"],"metadata":{"id":"wC-ynnuVOAL3"}},{"cell_type":"markdown","source":["## Importing libraries"],"metadata":{"id":"854Q0-VQOAOU"}},{"cell_type":"code","source":["!pip install pytorch-lightning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"pfC-1F58OaVG","executionInfo":{"status":"ok","timestamp":1746193302944,"user_tz":-540,"elapsed":105431,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"d8c6e2de-a2bd-4fb4-fc7c-4091af6bb2a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.6.0+cu124)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n","Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.13.2)\n","Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.15)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n","Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.1.post0 torchmetrics-1.7.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sXsIc4D1Nz1Z"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam\n","import pytorch_lightning as L\n","from torch.utils.data import TensorDataset, DataLoader"]},{"cell_type":"markdown","source":["## LSTM by hand"],"metadata":{"id":"esvNrHoJOqVS"}},{"cell_type":"markdown","source":["and of course, it is just simple example, we are not 100% applying the actual lstm calculation.\n","\n","we heavily simplying. for example, we are not considering even the long term memory when calculating the output gate."],"metadata":{"id":"ULudrxBBpbY9"}},{"cell_type":"markdown","source":["## 🧠 LSTM Cell Equations (per time step t)\n","\n","Let:\n","- \\( x_t \\): input at time \\( t \\)  \n","- \\( h_{t-1} \\): previous hidden state (short-term memory)  \n","- \\( C_{t-1} \\): previous cell state (long-term memory)\n","\n","---\n","\n","### 1. 🔻 Forget Gate  \n","Decides what to forget from cell state:\n","\\[\n","f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)\n","\\]\n","\n","---\n","\n","### 2. ✨ Input Gate  \n","Decides what new info to store:\n","\\[\n","i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)\n","\\]  \n","\\[\n","\\tilde{C}_t = \\tanh(W_c \\cdot [h_{t-1}, x_t] + b_c)\n","\\]\n","\n","---\n","\n","### 3. 💾 Update Cell State  \n","Combine remembered and new info:\n","\\[\n","C_t = f_t \\cdot C_{t-1} + i_t \\cdot \\tilde{C}_t\n","\\]\n","\n","---\n","\n","### 4. 📤 Output Gate  \n","Control what gets sent to next time step:\n","\\[\n","o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)\n","\\]  \n","\\[\n","h_t = o_t \\cdot \\tanh(C_t)\n","\\]\n","\n","controls flow of information.\n"],"metadata":{"id":"V7VBVP05pB5S"}},{"cell_type":"code","source":[],"metadata":{"id":"nGc5b0iYpCCv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LSTMbyHand(L.LightningModule):\n","    def __init__(self):\n","        super().__init__()\n","\n","        mean = torch.tensor(0.0)\n","        std = torch.tensor(1.0)\n","\n","        self.wlr1 = nn.Parameter(torch.normal(mean=mean,std=std),requires_grad=True) # used for calculating percentage of long-term to remember.\n","        self.wlr2 = nn.Parameter(torch.normal(mean=mean,std=std),requires_grad=True) # in other words they're the weights for forget gate.\n","        self.blr1 = nn.Parameter(torch.tensor(0.),requires_grad=True)\n","\n","        self.wpr1 = nn.Parameter(torch.normal(mean=mean,std=std),requires_grad=True)\n","        self.wpr2 = nn.Parameter(torch.normal(mean=mean,std=std),requires_grad=True) # used for calculating potential long-term 'Percentages'\n","        self.bpr1 = nn.Parameter(torch.tensor(0.),requires_grad=True)\n","         # above and belove blocks are for input gate.\n","        self.wp1 = nn.Parameter(torch.normal(mean=mean,std=std),requires_grad=True)  # used for calculating potential long-term memories\n","        self.wp2 = nn.Parameter(torch.normal(mean=mean,std=std),requires_grad=True)\n","        self.bp1 = nn.Parameter(torch.tensor(0.),requires_grad=True)\n","\n","        self.wo1 = nn.Parameter(torch.normal(mean=mean,std=std),requires_grad=True)  # those shits are for output gate.\n","        self.wo2 = nn.Parameter(torch.normal(mean=mean,std=std),requires_grad=True)\n","        self.bo1 = nn.Parameter(torch.tensor(0.),requires_grad=True)\n","\n","    def lstm_unit(self,input_value,long_memory,short_memory):\n","\n","        long_remember_percent = torch.sigmoid((short_memory*self.wlr1) + (input_value*self.wlr2) + self.blr1)\n","\n","        potential_remember_percent = torch.sigmoid((short_memory*self.wpr1) + (input_value*self.wpr2) + self.bpr1)\n","\n","        potential_memory = torch.tanh((short_memory*self.wp1) + (input_value*self.wp2) + self.bp1)\n","\n","        updated_long_memory = ((long_memory * long_remember_percent) + potential_remember_percent * potential_memory)\n","\n","        output_percent = torch.sigmoid((short_memory * self.wo1) + (input_value * self.wo2) + self.bo1)  # this fukcing like is incomplete. we need to add something that 'long term memory' also contributes in here.\n","\n","        updated_short_memory = torch.tanh(updated_long_memory) * output_percent\n","\n","        return ([updated_long_memory,updated_short_memory])\n","\n","    def forward(self,input):\n","\n","        long_memory = 0\n","        short_memory = 0\n","        day1 = input[0]\n","        day2 = input[1]\n","        day3 = input[2]\n","        day4 = input[3]\n","\n","        long_memory, short_memory = self.lstm_unit(day1,long_memory,short_memory)\n","        long_memory, short_memory = self.lstm_unit(day2,long_memory,short_memory)\n","        long_memory, short_memory = self.lstm_unit(day3,long_memory,short_memory)\n","        long_memory, short_memory = self.lstm_unit(day4,long_memory,short_memory)\n","\n","        return short_memory   # short memory means here, output after feeding info for 4 days.\n","\n","    def configure_optimizers(self):\n","\n","        return Adam(self.parameters())\n","\n","    def training_step(self,batch,batch_idx):\n","        input_i ,label_i = batch\n","        output_i = self.forward(input_i[0])\n","        loss = (output_i - label_i)**2\n","\n","        self.log(\"train_loss\",loss)\n","\n","        if (label_i == 0):\n","            self.log(\"out_0\", output_i)\n","        else :\n","            self.log(\"out_1\",output_i)\n","\n","        return loss"],"metadata":{"id":"HF7a-uZ9OAV_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training the Hand-Created Model"],"metadata":{"id":"BWEoQeQqWVNm"}},{"cell_type":"code","source":["model  = LSTMbyHand()\n"],"metadata":{"id":"axtNu8BmOAYh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = torch.tensor([[0.,0.5,0.25,1.],[1.,0.5,0.25,1.]])\n","labels = torch.tensor([0.,1.])\n"],"metadata":{"id":"KwMR5RduOAbR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = TensorDataset(inputs,labels)\n","dataloader = DataLoader(dataset)"],"metadata":{"id":"3qcvJ2AoOAd5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = L.Trainer(max_epochs=2000)\n","\n","trainer.fit(model,train_dataloaders = dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":361,"referenced_widgets":["5878d0631076460fa126e36a02f1a44f","53b701760f29410aa5e7b9a7ccd182e7","65d7549109774bd5852dcaccaf9640e4","4032a9b535c0460cb4ee5f5c4ac81d1b","ae51278453aa48cba52481fb5f149352","07a7cb782ef14ed28bcf9999d2aa5b33","0af8c444dbe64278afa3746c038e20b0","f906e925cae643c5aea685119ed566c9","e74a91e1f70f4324a8f7600f0bc0fb9c","9ecde36517364dffb394a78cef934918","341a5769818a4610b77cccca788ccd92"]},"id":"bvxxO2CXOAgy","executionInfo":{"status":"ok","timestamp":1746195226467,"user_tz":-540,"elapsed":92931,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"a4547fd1-f6b7-4744-a0eb-d4821521154f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name         | Type | Params | Mode\n","---------------------------------------------\n","  | other params | n/a  | 12     | n/a \n","---------------------------------------------\n","12        Trainable params\n","0         Non-trainable params\n","12        Total params\n","0.000     Total estimated model params size (MB)\n","0         Modules in train mode\n","0         Modules in eval mode\n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5878d0631076460fa126e36a02f1a44f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2000` reached.\n"]}]},{"cell_type":"markdown","source":["### Showing the predictions"],"metadata":{"id":"e013oUSLWQyE"}},{"cell_type":"code","source":["print(\"\\nNow let's compare the observed and predicted values ...\")\n","print(\"Company A: Observed = 0 , Predicted = \",model(torch.tensor([0.,0.5,0.25,1])).detach())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yVARX49SOAje","executionInfo":{"status":"ok","timestamp":1746195238761,"user_tz":-540,"elapsed":11,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"67879c0e-26c8-4ef0-87fa-9f96b7453271"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Now let's compare the observed and predicted values ...\n","Company A: Observed = 0 , Predicted =  tensor(0.0066)\n"]}]},{"cell_type":"code","source":["print(\"\\nNow let's compare the observed and predicted values ...\")\n","print(\"Company B: Observed = 1 , Predicted = \",model(torch.tensor([1.,0.5,0.25,1])).detach())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c2_aJjMwOAli","executionInfo":{"status":"ok","timestamp":1746195301759,"user_tz":-540,"elapsed":39,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"b298a04f-be05-454f-86da-ffd1f3802246"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Now let's compare the observed and predicted values ...\n","Company B: Observed = 1 , Predicted =  tensor(0.9148)\n"]}]},{"cell_type":"code","source":["!tensorboard --logdir=lightning_logs/\n","# jupyter lab-iin terminal deer ajillah yum shig bainoo."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"CFZhrSzPWN0v","executionInfo":{"status":"ok","timestamp":1746197471689,"user_tz":-540,"elapsed":4179,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"97ae84c4-ab06-4c81-8ea5-2e1495b24ed1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-05-02 14:51:08.465521: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1746197468.494307   17965 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1746197468.502626   17965 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n","ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/tensorboard\", line 10, in <module>\n","    sys.exit(run_main())\n","             ^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/main.py\", line 38, in run_main\n","    main_lib.global_init()\n","  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/main_lib.py\", line 50, in global_init\n","    if getattr(tf, \"__version__\", \"stub\") == \"stub\":\n","       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/lazy.py\", line 65, in __getattr__\n","    return getattr(load_once(self), attr_name)\n","                   ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/lazy.py\", line 97, in wrapper\n","    cache[arg] = f(arg)\n","                 ^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/lazy.py\", line 50, in load_once\n","    module = load_fn()\n","             ^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 45, in tf\n","    import tensorflow\n","  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 55, in <module>\n","    from tensorflow._api.v2 import compat\n","  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/compat/__init__.py\", line 8, in <module>\n","    from tensorflow._api.v2.compat import v1\n","  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py\", line 30, in <module>\n","    from tensorflow._api.v2.compat.v1 import compat\n","  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\", line 8, in <module>\n","    from tensorflow._api.v2.compat.v1.compat import v1\n","  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\", line 39, in <module>\n","    from tensorflow._api.v2.compat.v1 import feature_column\n","  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 1138, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 1078, in _find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1507, in find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1479, in _get_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1634, in find_spec\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"markdown","source":["### Training our model for 800 more epochs"],"metadata":{"id":"vT5JPUihXfus"}},{"cell_type":"code","source":["# by doing this shit, we can just continue training where we stopped.\n","# that's why in the next code block, we're making max_epochs to 2800. since we're just continue training where we stopped for 800 more epochs, that is just adding to the intial epoch counts.\n","path_to_best_checkpoint = trainer.checkpoint_callback.best_model_path"],"metadata":{"id":"AGOVInZDWpHR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = L.Trainer(max_epochs=2800)\n","trainer.fit(model,train_dataloaders=dataloader,ckpt_path=path_to_best_checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":416,"referenced_widgets":["62bba1196deb4f68b061fb0a30114178","7e47642b84e84b9f9cd2d48356203259","f2c93a12e54443c98820d75110f7ead9","6413ed9045474148b7abbd9b21293805","2bb9784b37d04999b6b222b9a97a4223","6730fec5b6e7409c9e375010980a4afa","b1c16cc9bb1148f387ad6bddbca96381","37f2ea1b43c0447d94d7802c22532d97","e86419bb9d09466e9a3de8ebb294a3b5","18d3fb45e7854525827293ef56643356","4e01459f799642f49b0e926ee38a23f0"]},"collapsed":true,"id":"f0oh3A29WdFD","executionInfo":{"status":"ok","timestamp":1746195699551,"user_tz":-540,"elapsed":33414,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"2b3ac919-b85d-4f5e-a987-15d2f6756111"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.utilities.rank_zero:Restoring states from the checkpoint path at /content/lightning_logs/version_4/checkpoints/epoch=1999-step=4000.ckpt\n","/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:362: The dirpath has changed from '/content/lightning_logs/version_4/checkpoints' to '/content/lightning_logs/version_5/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name         | Type | Params | Mode\n","---------------------------------------------\n","  | other params | n/a  | 12     | n/a \n","---------------------------------------------\n","12        Trainable params\n","0         Non-trainable params\n","12        Total params\n","0.000     Total estimated model params size (MB)\n","0         Modules in train mode\n","0         Modules in eval mode\n","INFO:pytorch_lightning.utilities.rank_zero:Restored all states from the checkpoint at /content/lightning_logs/version_4/checkpoints/epoch=1999-step=4000.ckpt\n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62bba1196deb4f68b061fb0a30114178"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2800` reached.\n"]}]},{"cell_type":"code","source":["print(\"\\nNow let's compare the observed and predicted values ...\")\n","print(\"Company A: Observed = 0 , Predicted = \",model(torch.tensor([0.,0.5,0.25,1])).detach())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pIIHNxgmWdHx","executionInfo":{"status":"ok","timestamp":1746195699558,"user_tz":-540,"elapsed":5,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"7a8ac164-b52d-48f7-ead1-f818243e37a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Now let's compare the observed and predicted values ...\n","Company A: Observed = 0 , Predicted =  tensor(0.0012)\n"]}]},{"cell_type":"code","source":["print(\"\\nNow let's compare the observed and predicted values ...\")\n","print(\"Company B: Observed = 1 , Predicted = \",model(torch.tensor([1.,0.5,0.25,1])).detach())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FXGzL8tmWdKI","executionInfo":{"status":"ok","timestamp":1746195699564,"user_tz":-540,"elapsed":5,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"e535075a-db41-4e3c-baa3-a9616adf2e4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Now let's compare the observed and predicted values ...\n","Company B: Observed = 1 , Predicted =  tensor(0.9523)\n"]}]},{"cell_type":"markdown","source":["### Again for 1000 more epochs"],"metadata":{"id":"6CPXsPZLYJIN"}},{"cell_type":"code","source":["path_to_best_checkpoint = trainer.checkpoint_callback.best_model_path"],"metadata":{"id":"HJ0MFmoMX5S6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = L.Trainer(max_epochs=3800)\n","trainer.fit(model,train_dataloaders=dataloader,ckpt_path=path_to_best_checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":416,"referenced_widgets":["e203536c96474a71a0fedcd3af5d3dfb","795db0bada5a4ea69e0fb166fb2dc7cf","bbe83ca620214f3e9f66da60d819d701","66f6fb4296794014bcdbb37e4b4303a1","31c81bc60442458c8f02c879bfdf2c4b","94a606637ef3427fa8e40e6a11168c50","b2608ab09a8a452c8ed262ce7e492698","010b1de529d7479db2ed2a889a106ee7","5bd19ba5aa574ca79bae3112a5a101b6","3e07c246a7734e68a317731ae8cca75e","2221bffae75d4e2ab155207bd278e044"]},"collapsed":true,"id":"R2p5jKvZX5U_","executionInfo":{"status":"ok","timestamp":1746195837047,"user_tz":-540,"elapsed":45525,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"469efc01-8bf7-4bea-85c4-2d3509088ebe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.utilities.rank_zero:Restoring states from the checkpoint path at /content/lightning_logs/version_5/checkpoints/epoch=2799-step=5600.ckpt\n","/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:362: The dirpath has changed from '/content/lightning_logs/version_5/checkpoints' to '/content/lightning_logs/version_6/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name         | Type | Params | Mode\n","---------------------------------------------\n","  | other params | n/a  | 12     | n/a \n","---------------------------------------------\n","12        Trainable params\n","0         Non-trainable params\n","12        Total params\n","0.000     Total estimated model params size (MB)\n","0         Modules in train mode\n","0         Modules in eval mode\n","INFO:pytorch_lightning.utilities.rank_zero:Restored all states from the checkpoint at /content/lightning_logs/version_5/checkpoints/epoch=2799-step=5600.ckpt\n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e203536c96474a71a0fedcd3af5d3dfb"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=3800` reached.\n"]}]},{"cell_type":"code","source":["print(\"\\nNow let's compare the observed and predicted values ...\")\n","print(\"Company A: Observed = 0 , Predicted = \",model(torch.tensor([0.,0.5,0.25,1])).detach())\n","\n","print(\"\\nNow let's compare the observed and predicted values ...\")\n","print(\"Company B: Observed = 1 , Predicted = \",model(torch.tensor([1.,0.5,0.25,1])).detach())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aK2vwHh2Wdl1","executionInfo":{"status":"ok","timestamp":1746195837054,"user_tz":-540,"elapsed":9,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"1a487bdd-b9e5-4b50-e10a-86d92edad8d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Now let's compare the observed and predicted values ...\n","Company A: Observed = 0 , Predicted =  tensor(0.0003)\n","\n","Now let's compare the observed and predicted values ...\n","Company B: Observed = 1 , Predicted =  tensor(0.9716)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mhhx30LlWdpc"},"execution_count":null,"outputs":[]}]}