{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOMLGrsMRiQrIF/0F7AzG6c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# CNN(Convolutional Neural Network)"],"metadata":{"id":"bUtsdQhHu79t"}},{"cell_type":"markdown","source":["## Importing the libraries"],"metadata":{"id":"FWGpL7P8u7_q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"R0j91HeGuXTK"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","source":["tf.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":110},"id":"vo7-8II1u9YQ","executionInfo":{"status":"ok","timestamp":1735309586330,"user_tz":-540,"elapsed":16,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"f4d16f14-98cd-48f7-e7fe-96dba03069ab"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.17.1'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["## Part-1 Data Preprocessing"],"metadata":{"id":"GIN2XbOeMFiR"}},{"cell_type":"markdown","source":["### Preprocessing the Training set"],"metadata":{"id":"cnFLho7fMJxC"}},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(\n","    rescale = 1./255,  # Scales pixel values to the range [0,1] instead of the original [0,255].\n","    shear_range = 0.2,\n","    zoom_range = 0.2,\n","    horizontal_flip = True)\n","import os\n","\n","training_set = train_datagen.flow_from_directory(\n","    os.path.expanduser('~/Desktop/python/CNN/dataset/training_set'),\n","    target_size = (64,64),\n","    batch_size = 32,\n","    class_mode = 'binary')  # cat or dog l gel classification bolohoor, binary shit shaajin..\n","\n","\n","# ene lalriig ugasaa jupyter notebook ajilluulah yum baina.\n","# Desktop/python/CNN ruu orj baigaad..."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"collapsed":true,"id":"AE5EVymGLZI-","executionInfo":{"status":"error","timestamp":1735309586330,"user_tz":-540,"elapsed":11,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"39c1bb01-6c11-4f66-a168-b3d0f4c2be4e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/root/Desktop/python/CNN/dataset/training_set'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-d2b9636d8c6b>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m training_set = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~/Desktop/python/CNN/dataset/training_set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/Desktop/python/CNN/dataset/training_set'"]}]},{"cell_type":"markdown","source":["### Preprocessing the Test set"],"metadata":{"id":"Teyxe7VLMNPN"}},{"cell_type":"code","source":["test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","test_set = test_datagen.flow_from_directory(\n","    'data/test',\n","    target_size = (64,64),\n","    batch_size = 32,\n","    class_mode = 'binary')"],"metadata":{"id":"X-fNpC9mORp9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part-2 Building the CNN"],"metadata":{"id":"47_MNSHSMNlV"}},{"cell_type":"markdown","source":["### Initialising the CNN"],"metadata":{"id":"8isUdIQhM9aD"}},{"cell_type":"code","source":["cnn = tf.keras.models.Sequential()"],"metadata":{"id":"ZIA-58DQOOYi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step-1 Convolution"],"metadata":{"id":"HP2HZoC9M9cK"}},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))\n"],"metadata":{"id":"x1XqWAJhOOyh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step-2 Pooling"],"metadata":{"id":"Hm6ZlwOnM9eJ"}},{"cell_type":"code","source":["cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"],"metadata":{"id":"r24_2Ot1OPOe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Adding a second convolutional layer"],"metadata":{"id":"ciheh8UGM9gB"}},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n","# and pooling again.\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"],"metadata":{"id":"WOfXvhgtOPvG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step-3 Flattening"],"metadata":{"id":"CdXEemV6NKjL"}},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Flatten())"],"metadata":{"id":"zNV9U3PROQSa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step-4 Full connection"],"metadata":{"id":"nZLFqsmKNKlF"}},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))"],"metadata":{"id":"rAUJWYBQONy8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step-5 Output Layer"],"metadata":{"id":"R8_9rGF3NQW5"}},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid',))"],"metadata":{"id":"S35rNM5hONeg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part-3 Training the CNN"],"metadata":{"id":"BHBY_N91NSiU"}},{"cell_type":"markdown","source":["### Compiling the CNN"],"metadata":{"id":"WdgN6OJiNU22"}},{"cell_type":"code","source":["cnn.compile(optimizer = 'adam',loss='binary_crossentropy',metrics=['accuracy'])"],"metadata":{"id":"NzUhkA7HOMgt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training CNN on the Training set and evaluating it on the Test set"],"metadata":{"id":"nSrZ8V17NU41"}},{"cell_type":"code","source":["cnn.fit(x=training_set,validation_data=test_set,epochs=25)"],"metadata":{"id":"UyAVIDV6ONCy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part-4 Making a single prediction"],"metadata":{"id":"BSp7HzusOIQ2"}},{"cell_type":"code","source":["import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('/home/goku/Desktop/python/CNN/dataset/single_prediction/cat_or_dog_1.jpg',target_size=(64,64))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image,axis=0) # Adds an extra dimension to match the batch format.\n","\n","result = cnn.predict(test_image)\n","training_set.class_indices\n","if result[0][0] == 1 :\n","    prediction = \"dog\"\n","else :\n","    prediction = \"cat\"\n","\n","print(prediction)"],"metadata":{"id":"M_8iNqv4MNud"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"I8c61OMfMNwX"},"execution_count":null,"outputs":[]}]}