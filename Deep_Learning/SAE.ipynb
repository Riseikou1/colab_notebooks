{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOZUdAchFjMTCxZehg1s7XE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# AutoEncoders"],"metadata":{"id":"6F3mHWdeNdMH"}},{"cell_type":"markdown","source":["## Importing the libraries"],"metadata":{"id":"Km5jgl2wNdPJ"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.parallel\n","import torch.utils.data\n","from torch.autograd import Variable"],"metadata":{"id":"1ay_ujfHNddj","executionInfo":{"status":"ok","timestamp":1735733307035,"user_tz":-540,"elapsed":303,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Importing the dataset"],"metadata":{"id":"aHnokBCrNiWb"}},{"cell_type":"code","source":["movies = pd.read_csv(\"movies.dat\",sep='::',header=None,engine='python',encoding='latin-1')\n","users = pd.read_csv(\"users.dat\",encoding='latin-1',header=None,engine='python',sep='::')\n","ratings = pd.read_csv(\"ratings.dat\",engine='python',encoding='latin-1',header=None,sep='::')"],"metadata":{"id":"RLmm1iKzNjUF","executionInfo":{"status":"ok","timestamp":1735733123613,"user_tz":-540,"elapsed":5537,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Preparing the training set and the test set"],"metadata":{"id":"22DffymANicK"}},{"cell_type":"code","source":["training_set = pd.read_csv(\"u1.base\",delimiter='\\t')\n","training_set = np.array(training_set,dtype='int')\n","test_set= pd.read_csv('u1.test',delimiter='\\t')\n","test_set = np.array(test_set,dtype='int')"],"metadata":{"id":"dGNUVZaoNjtV","executionInfo":{"status":"ok","timestamp":1735733123614,"user_tz":-540,"elapsed":6,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Getting the number of users and movies"],"metadata":{"id":"FihwzTgfNig_"}},{"cell_type":"code","source":["nb_users = int(max(max(training_set[:,0]),max(test_set[:,0])))\n","nb_movies = int(max(max(training_set[:,1]),max(test_set[:,1])))"],"metadata":{"id":"DJy6i68ENkPt","executionInfo":{"status":"ok","timestamp":1735733123615,"user_tz":-540,"elapsed":6,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Converting the data into an array with users in lines and movies in columns"],"metadata":{"id":"uj2x-G2hNilb"}},{"cell_type":"code","source":["def convert(data) :\n","    new_data = list()\n","    for id_users in range(1,nb_users+1) :\n","        id_movies = data[:,1][data[:,0]==id_users]\n","        id_ratings = data[:,2][data[:,0]==id_users]\n","        ratings = np.zeros(nb_movies)\n","        ratings[id_movies-1] = id_ratings\n","        new_data.append(list(ratings))\n","    return new_data\n","training_set = convert(training_set)\n","test_set = convert(test_set)"],"metadata":{"id":"wvcr-SLhNk1p","executionInfo":{"status":"ok","timestamp":1735733124062,"user_tz":-540,"elapsed":453,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Converting the data into Torch tensors"],"metadata":{"id":"GVgnV38DNipf"}},{"cell_type":"code","source":["training_set = torch.FloatTensor(training_set)\n","test_set = torch.FloatTensor(test_set)"],"metadata":{"id":"vsIHOn0DNlGa","executionInfo":{"status":"ok","timestamp":1735733124467,"user_tz":-540,"elapsed":408,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Creating the archtecture of the Neural Network"],"metadata":{"id":"jgU8i5wiNisn"}},{"cell_type":"code","source":["class SAE(nn.Module) :\n","    def __init__(self,):\n","        super(SAE,self).__init__()\n","        self.fc1 = nn.Linear(nb_movies,20)\n","        self.fc2 = nn.Linear(20,10)\n","        self.fc3 = nn.Linear(10,20)\n","        self.fc4 = nn.Linear(20,nb_movies)\n","        self.activation = nn.Sigmoid()\n","    def forward(self,x):\n","        x = self.activation(self.fc1(x))\n","        x = self.activation(self.fc2(x))\n","        x = self.activation(self.fc3(x))\n","        x = self.fc4(x)\n","        return x\n","sae = SAE()\n","criterion = nn.MSELoss()\n","optimizer = optim.RMSprop(sae.parameters(),lr=0.01,weight_decay=0.5)"],"metadata":{"id":"jm4UsjBINm3d","executionInfo":{"status":"ok","timestamp":1735733518558,"user_tz":-540,"elapsed":5947,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Training the SAE"],"metadata":{"id":"ffrBnUz9Nivl"}},{"cell_type":"code","source":["nb_epoch = 200\n","for epoch in range(1,nb_epoch+1):\n","    train_loss = 0\n","    s = 0.\n","    for id_user in range(nb_users):\n","        input = Variable(training_set[id_user]).unsqueeze(0) # adds and additional dimension to the data(batch_size),making it compatible with the model input.\n","        target = input.clone()   # since we're trying to reconstruct the input, the input is being cloned.\n","        if torch.sum(target.data>0)>0 :  # counts non-zero entries in the user's rating data.\n","            output = sae(input)\n","            target.require_grad = False # target tensor shouldn't be calculating grads during backpropagation, since it's used only for comparison , not for opmization.\n","            output[target==0] = 0 # sets the values of unrated movies(target=0) to 0.. cuz weight update and backpropagation don't count those kinda shit.so it is just for saving up some memories.\n","            loss = criterion(output,target)\n","            mean_corrector = nb_movies/float(torch.sum(target.data>0)+1e-10) # normalizing the loss by the number of non-zero movies. it is either for mean_squared blah2 shit or for preventing bias.\n","            loss.backward()\n","            train_loss += np.sqrt(loss.data*mean_corrector)\n","            s += 1.\n","            optimizer.step()\n","    print('epoch: '+str(epoch)+ ' loss: '+str(train_loss/s))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"lPs4jNPeNl4_","executionInfo":{"status":"ok","timestamp":1735734624653,"user_tz":-540,"elapsed":407100,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"d19bf632-01b8-4b6e-a9b8-63071443294a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1 loss: tensor(1.7709)\n","epoch: 2 loss: tensor(1.0967)\n","epoch: 3 loss: tensor(1.0533)\n","epoch: 4 loss: tensor(1.0385)\n","epoch: 5 loss: tensor(1.0306)\n","epoch: 6 loss: tensor(1.0267)\n","epoch: 7 loss: tensor(1.0238)\n","epoch: 8 loss: tensor(1.0220)\n","epoch: 9 loss: tensor(1.0205)\n","epoch: 10 loss: tensor(1.0195)\n","epoch: 11 loss: tensor(1.0189)\n","epoch: 12 loss: tensor(1.0183)\n","epoch: 13 loss: tensor(1.0177)\n","epoch: 14 loss: tensor(1.0176)\n","epoch: 15 loss: tensor(1.0174)\n","epoch: 16 loss: tensor(1.0171)\n","epoch: 17 loss: tensor(1.0166)\n","epoch: 18 loss: tensor(1.0165)\n","epoch: 19 loss: tensor(1.0163)\n","epoch: 20 loss: tensor(1.0159)\n","epoch: 21 loss: tensor(1.0160)\n","epoch: 22 loss: tensor(1.0160)\n","epoch: 23 loss: tensor(1.0158)\n","epoch: 24 loss: tensor(1.0157)\n","epoch: 25 loss: tensor(1.0156)\n","epoch: 26 loss: tensor(1.0156)\n","epoch: 27 loss: tensor(1.0150)\n","epoch: 28 loss: tensor(1.0151)\n","epoch: 29 loss: tensor(1.0131)\n","epoch: 30 loss: tensor(1.0115)\n","epoch: 31 loss: tensor(1.0094)\n","epoch: 32 loss: tensor(1.0095)\n","epoch: 33 loss: tensor(1.0059)\n","epoch: 34 loss: tensor(1.0056)\n","epoch: 35 loss: tensor(1.0015)\n","epoch: 36 loss: tensor(1.0010)\n","epoch: 37 loss: tensor(0.9979)\n","epoch: 38 loss: tensor(0.9955)\n","epoch: 39 loss: tensor(0.9932)\n","epoch: 40 loss: tensor(0.9941)\n","epoch: 41 loss: tensor(0.9894)\n","epoch: 42 loss: tensor(0.9885)\n","epoch: 43 loss: tensor(0.9854)\n","epoch: 44 loss: tensor(0.9862)\n","epoch: 45 loss: tensor(0.9819)\n","epoch: 46 loss: tensor(0.9814)\n","epoch: 47 loss: tensor(0.9767)\n","epoch: 48 loss: tensor(0.9803)\n","epoch: 49 loss: tensor(0.9759)\n","epoch: 50 loss: tensor(0.9746)\n","epoch: 51 loss: tensor(0.9756)\n","epoch: 52 loss: tensor(0.9756)\n","epoch: 53 loss: tensor(0.9713)\n","epoch: 54 loss: tensor(0.9696)\n","epoch: 55 loss: tensor(0.9671)\n","epoch: 56 loss: tensor(0.9694)\n","epoch: 57 loss: tensor(0.9677)\n","epoch: 58 loss: tensor(0.9713)\n","epoch: 59 loss: tensor(0.9670)\n","epoch: 60 loss: tensor(0.9696)\n","epoch: 61 loss: tensor(0.9662)\n","epoch: 62 loss: tensor(0.9687)\n","epoch: 63 loss: tensor(0.9653)\n","epoch: 64 loss: tensor(0.9609)\n","epoch: 65 loss: tensor(0.9616)\n","epoch: 66 loss: tensor(0.9591)\n","epoch: 67 loss: tensor(0.9573)\n","epoch: 68 loss: tensor(0.9557)\n","epoch: 69 loss: tensor(0.9547)\n","epoch: 70 loss: tensor(0.9544)\n","epoch: 71 loss: tensor(0.9511)\n","epoch: 72 loss: tensor(0.9508)\n","epoch: 73 loss: tensor(0.9499)\n","epoch: 74 loss: tensor(0.9497)\n","epoch: 75 loss: tensor(0.9492)\n","epoch: 76 loss: tensor(0.9485)\n","epoch: 77 loss: tensor(0.9464)\n","epoch: 78 loss: tensor(0.9460)\n","epoch: 79 loss: tensor(0.9458)\n","epoch: 80 loss: tensor(0.9446)\n","epoch: 81 loss: tensor(0.9439)\n","epoch: 82 loss: tensor(0.9444)\n","epoch: 83 loss: tensor(0.9428)\n","epoch: 84 loss: tensor(0.9426)\n","epoch: 85 loss: tensor(0.9418)\n","epoch: 86 loss: tensor(0.9435)\n","epoch: 87 loss: tensor(0.9509)\n","epoch: 88 loss: tensor(0.9486)\n","epoch: 89 loss: tensor(0.9457)\n","epoch: 90 loss: tensor(0.9479)\n","epoch: 91 loss: tensor(0.9453)\n","epoch: 92 loss: tensor(0.9477)\n","epoch: 93 loss: tensor(0.9454)\n","epoch: 94 loss: tensor(0.9442)\n","epoch: 95 loss: tensor(0.9448)\n","epoch: 96 loss: tensor(0.9455)\n","epoch: 97 loss: tensor(0.9417)\n","epoch: 98 loss: tensor(0.9417)\n","epoch: 99 loss: tensor(0.9398)\n","epoch: 100 loss: tensor(0.9392)\n","epoch: 101 loss: tensor(0.9422)\n","epoch: 102 loss: tensor(0.9421)\n","epoch: 103 loss: tensor(0.9399)\n","epoch: 104 loss: tensor(0.9446)\n","epoch: 105 loss: tensor(0.9395)\n","epoch: 106 loss: tensor(0.9392)\n","epoch: 107 loss: tensor(0.9379)\n","epoch: 108 loss: tensor(0.9392)\n","epoch: 109 loss: tensor(0.9361)\n","epoch: 110 loss: tensor(0.9375)\n","epoch: 111 loss: tensor(0.9370)\n","epoch: 112 loss: tensor(0.9384)\n","epoch: 113 loss: tensor(0.9337)\n","epoch: 114 loss: tensor(0.9359)\n","epoch: 115 loss: tensor(0.9357)\n","epoch: 116 loss: tensor(0.9344)\n","epoch: 117 loss: tensor(0.9321)\n","epoch: 118 loss: tensor(0.9324)\n","epoch: 119 loss: tensor(0.9310)\n","epoch: 120 loss: tensor(0.9318)\n","epoch: 121 loss: tensor(0.9296)\n","epoch: 122 loss: tensor(0.9305)\n","epoch: 123 loss: tensor(0.9288)\n","epoch: 124 loss: tensor(0.9292)\n","epoch: 125 loss: tensor(0.9282)\n","epoch: 126 loss: tensor(0.9291)\n","epoch: 127 loss: tensor(0.9271)\n","epoch: 128 loss: tensor(0.9286)\n","epoch: 129 loss: tensor(0.9276)\n","epoch: 130 loss: tensor(0.9262)\n","epoch: 131 loss: tensor(0.9261)\n","epoch: 132 loss: tensor(0.9263)\n","epoch: 133 loss: tensor(0.9252)\n","epoch: 134 loss: tensor(0.9258)\n","epoch: 135 loss: tensor(0.9240)\n","epoch: 136 loss: tensor(0.9246)\n","epoch: 137 loss: tensor(0.9228)\n","epoch: 138 loss: tensor(0.9238)\n","epoch: 139 loss: tensor(0.9222)\n","epoch: 140 loss: tensor(0.9238)\n","epoch: 141 loss: tensor(0.9219)\n","epoch: 142 loss: tensor(0.9234)\n","epoch: 143 loss: tensor(0.9221)\n","epoch: 144 loss: tensor(0.9225)\n","epoch: 145 loss: tensor(0.9233)\n","epoch: 146 loss: tensor(0.9227)\n","epoch: 147 loss: tensor(0.9208)\n","epoch: 148 loss: tensor(0.9216)\n","epoch: 149 loss: tensor(0.9196)\n","epoch: 150 loss: tensor(0.9208)\n","epoch: 151 loss: tensor(0.9196)\n","epoch: 152 loss: tensor(0.9209)\n","epoch: 153 loss: tensor(0.9193)\n","epoch: 154 loss: tensor(0.9202)\n","epoch: 155 loss: tensor(0.9189)\n","epoch: 156 loss: tensor(0.9197)\n","epoch: 157 loss: tensor(0.9187)\n","epoch: 158 loss: tensor(0.9195)\n","epoch: 159 loss: tensor(0.9186)\n","epoch: 160 loss: tensor(0.9192)\n","epoch: 161 loss: tensor(0.9178)\n","epoch: 162 loss: tensor(0.9185)\n","epoch: 163 loss: tensor(0.9173)\n","epoch: 164 loss: tensor(0.9181)\n","epoch: 165 loss: tensor(0.9171)\n","epoch: 166 loss: tensor(0.9178)\n","epoch: 167 loss: tensor(0.9167)\n","epoch: 168 loss: tensor(0.9175)\n","epoch: 169 loss: tensor(0.9164)\n","epoch: 170 loss: tensor(0.9173)\n","epoch: 171 loss: tensor(0.9161)\n","epoch: 172 loss: tensor(0.9169)\n","epoch: 173 loss: tensor(0.9157)\n","epoch: 174 loss: tensor(0.9166)\n","epoch: 175 loss: tensor(0.9154)\n","epoch: 176 loss: tensor(0.9166)\n","epoch: 177 loss: tensor(0.9150)\n","epoch: 178 loss: tensor(0.9160)\n","epoch: 179 loss: tensor(0.9147)\n","epoch: 180 loss: tensor(0.9158)\n","epoch: 181 loss: tensor(0.9146)\n","epoch: 182 loss: tensor(0.9154)\n","epoch: 183 loss: tensor(0.9143)\n","epoch: 184 loss: tensor(0.9150)\n","epoch: 185 loss: tensor(0.9140)\n","epoch: 186 loss: tensor(0.9151)\n","epoch: 187 loss: tensor(0.9139)\n","epoch: 188 loss: tensor(0.9147)\n","epoch: 189 loss: tensor(0.9137)\n","epoch: 190 loss: tensor(0.9143)\n","epoch: 191 loss: tensor(0.9129)\n","epoch: 192 loss: tensor(0.9138)\n","epoch: 193 loss: tensor(0.9128)\n","epoch: 194 loss: tensor(0.9139)\n","epoch: 195 loss: tensor(0.9124)\n","epoch: 196 loss: tensor(0.9135)\n","epoch: 197 loss: tensor(0.9122)\n","epoch: 198 loss: tensor(0.9132)\n","epoch: 199 loss: tensor(0.9123)\n","epoch: 200 loss: tensor(0.9128)\n"]}]},{"cell_type":"markdown","source":["## Testing the SAE"],"metadata":{"id":"Cr8_8dV_Niy6"}},{"cell_type":"code","source":["test_loss = 0\n","s = 0.\n","for id_user in range(nb_users) :\n","    input = Variable(training_set[id_user]).unsqueeze(0)\n","    target = Variable(test_set[id_user]).unsqueeze(0)\n","    if torch.sum(target.data>0) >0 :\n","        output = sae(input)\n","        target.require_grad = False\n","        output[target==0]=0\n","        loss =criterion(output,target)\n","        mean_corrector = nb_movies/float(torch.sum(target.data>0)+1e-10)\n","        test_loss += np.sqrt(loss.data*mean_corrector)\n","        s += 1.\n","print(\"test loss: \"+ str(test_loss/s))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AEbq-_C-NmjF","executionInfo":{"status":"ok","timestamp":1735739069515,"user_tz":-540,"elapsed":787,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"6761c52a-5576-46f2-faf4-b0e33acfcdc6"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["test loss: tensor(0.9570)\n"]}]}]}