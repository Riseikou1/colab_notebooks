{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMDROH1JqILnaPZ50PXFdEV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Evolution Strategies and Genetic Algorithms"],"metadata":{"id":"pMa7vOsH7POQ"}},{"cell_type":"code","source":["!pip install gymnasium\n","!pip install swig"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ENjrXx7bB1oy","executionInfo":{"status":"ok","timestamp":1731845411206,"user_tz":-540,"elapsed":9085,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"c1b72d14-a42f-4e65-f047-8ec2ee2ca69e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gymnasium\n","  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n","Collecting farama-notifications>=0.0.1 (from gymnasium)\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n","Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Installing collected packages: farama-notifications, gymnasium\n","Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0\n","Collecting swig\n","  Downloading swig-4.2.1.post0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n","Downloading swig-4.2.1.post0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: swig\n","Successfully installed swig-4.2.1.post0\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"collapsed":true,"id":"WrUuc2Wp6tk9","executionInfo":{"status":"error","timestamp":1731845418504,"user_tz":-540,"elapsed":7304,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}},"outputId":"cdb4fc68-63f5-4dd6-9734-73a6d6e37837"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'gymnasium.logger' has no attribute 'set_level'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-54955fced567>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Supresses Gym warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: module 'gymnasium.logger' has no attribute 'set_level'"]}],"source":["import gymnasium as gym\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import multiprocessing as mp\n","import os\n","import copy\n","import random\n","from torch.multiprocessing import Pool\n","\n","gym.logger.set_level(40) # Supresses Gym warnings"]},{"cell_type":"markdown","source":["## Building the Policy Network"],"metadata":{"id":"wYJQJ5mv7xUH"}},{"cell_type":"code","source":["class PolicyNet(nn.Module):\n","    def __init__(self,input_size,output_size,hidden_size=256):\n","        super(PolicyNet,self).__init__()\n","        self.network = nn.Sequential(nn.Linear(input_size),nn.Relu(),nn.Linear(hidden_size,hidden_state),nn.Relu(),nn.Linear(hidden_state,output_size),nn.Tanh(),)\n","    def forward(self,x):\n","        return self.network(x)"],"metadata":{"collapsed":true,"id":"XJBH0s-h7np5","executionInfo":{"status":"aborted","timestamp":1731845418506,"user_tz":-540,"elapsed":5,"user":{"displayName":"temka-sama","userId":"13085788523966765980"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluating the policy"],"metadata":{"id":"Tn4IQJxh9tKP"}},{"cell_type":"code","source":["def evaluate_policy(policy_net, env_name='Humanoid-v4', seed=123, eval_episodes=3):\n","    env = gym.make(env_name)\n","    env.seed(seed)\n","    rewards = []\n","    for _ in range(eval_episodes):\n","        state = env.reset()\n","        done = False\n","        total_reward = 0\n","        while not done:\n","            state = torch.FloatTensor(state).unsqueeze(0)\n","            action = policy_net(state).detach().numpy()[0]\n","            state, reward, done, _ = env.step(action)\n","            total_reward += reward\n","        rewards.append(total_reward)\n","    env.close()\n","    return np.mean(rewards)\n"],"metadata":{"id":"HKwfAtDV9k2a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Altering the neural network weights and biases of the policy to introduce variability(Mutation)"],"metadata":{"id":"w0uMYWoM-hug"}},{"cell_type":"code","source":["def mutate_policy(policy_net, mutation_power=0.02):\n","    mutated_net = copy.deepcopy(policy_net)\n","    with torch.no_grad():\n","        for param in mutated_net.parameters():\n","            param += mutation_power * torch.randn_like(param)\n","    return mutated_net\n"],"metadata":{"id":"0SgQQl9R-h2D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Combining parameters from two parent policies to create a child policy (Crossover)"],"metadata":{"id":"UR9r9GG8-h8Z"}},{"cell_type":"code","source":["def crossover_policy(policy_net1, policy_net2):\n","    child_net = copy.deepcopy(policy_net1)\n","    with torch.no_grad():\n","        for param1, param2, child_param in zip(policy_net1.parameters(), policy_net2.parameters(), child_net.parameters()):\n","            mask = torch.bernoulli(torch.full_like(param1, 0.5))\n","            child_param.copy_(mask * param1 + (1-mask) * param2)\n","    return child_net\n","\n","\n","# Implementing Parallel Evaluation to optimize the computational demands\n","\n","\n","def parallel_evaluate(nets, env_name):\n","    with Pool(mp.cpu_count()) as p:\n","        scores = p.starmap(evaluate_policy, [(net, env_name) for net in nets])\n","    return scores\n"],"metadata":{"id":"TR-RhN0G-iBf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Implementing the Evolution Strategy Loop (Training)\n","\n"],"metadata":{"id":"1Tr3EJ4V-iHS"}},{"cell_type":"code","source":["def evolution_strategy(generations=10, population_size=50, top_k=10, env_name='Humanoid-v4'):\n","    input_size = gym.make(env_name).observation_space.shape[0]\n","    output_size = gym.make(env_name).action_space.shape[0]\n","    # Initializing the current population\n","    population = [PolicyNet(input_size, output_size) for _ in range(population_size)]\n","    for generation in range(generations):\n","        # Evaluating the current population\n","        scores = parallel_evaluate(population, env_name)\n","        # Selecting the top performers\n","        top_indices = np.argsort(scores)[-top_k:]\n","        top_nets = [population[i] for i in top_indices]\n","        print(f'Generation {generation}, Top Score: {max(scores)}')\n","        # Breeding the next population\n","        next_population = []\n","        while len(next_population) < population_size:\n","            parent1, parent2 = random.sample(top_nets, 2)\n","            child_net = crossover_policy(parent1, parent2)\n","            child_net = mutate_policy(child_net)\n","            next_population.append(child_net)\n","        population = next_population\n","\n","\n","# Starting the training\n","\n","if __name__ == '__main__':\n","    evolution_strategy()\n"],"metadata":{"id":"ZRca8HYK-iMN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"IVI-Qcbf-iRL"}},{"cell_type":"code","source":[],"metadata":{"id":"PahOjW1X-iVz"},"execution_count":null,"outputs":[]}]}